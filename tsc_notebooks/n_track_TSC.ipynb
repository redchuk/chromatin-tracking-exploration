{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2363,
     "status": "ok",
     "timestamp": 1645173632643,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "7qcPz9BUMrHs",
    "outputId": "c44f669e-aacf-48d1-f28f-261ff694287c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "ROOT = '/content/drive'     # default for the drive\n",
    "drive.mount(ROOT)\n",
    "\n",
    "GITROOT = \"/content/drive/My Drive/Git\"\n",
    "WRKROOT = \"/content/drive/My Drive/Work\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if on Turso\n",
    "GITROOT = \"/proj/hajaalin/Projects\"\n",
    "WRKROOT = \"/wrk/users/hajaalin/output/TSC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INCEPTIONTIME = GITROOT + \"/InceptionTime\"\n",
    "SCRIPTS = GITROOT + \"/n_track_ML/scripts\"\n",
    "\n",
    "CV_OUT = WRKROOT + \"/cross-validation/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26225,
     "status": "ok",
     "timestamp": 1645173658849,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "utdQ5dAxmOBs",
    "outputId": "0f8a64d2-91e1-408f-c4a4-c3784d3053cd"
   },
   "outputs": [],
   "source": [
    "!pip install dtaidistance\n",
    "!pip install scikeras\n",
    "!pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2184,
     "status": "ok",
     "timestamp": 1645173661013,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "aK3pQt_Dl_YY",
    "outputId": "08af39fc-e233-4bdc-d358-300b20956a47"
   },
   "outputs": [],
   "source": [
    "!pip freeze |sed s/==.*//> pip_freeze_colab_tsc_no_versions_gpu.txt\n",
    "!pwd\n",
    "!diff pip_freeze_colab_tsc_no_versions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 373,
     "status": "ok",
     "timestamp": 1645173661365,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "w6hLgLosmwe5",
    "outputId": "6194b233-a05f-4fa7-a588-62200ca3e6b0"
   },
   "outputs": [],
   "source": [
    "!mv pip_freeze_colab_tsc.txt /content/drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPRI5CoGl5vh"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import linregress\n",
    "from sktime.datatypes._panel._convert import (\n",
    "    from_multi_index_to_nested,\n",
    "    from_multi_index_to_3d_numpy,\n",
    "    from_nested_to_multi_index,\n",
    "    from_nested_to_3d_numpy,\n",
    ")\n",
    "#from sktime.utils.data_io import make_multi_index_dataframe\n",
    "from sktime.datasets import make_multi_index_dataframe\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, INCEPTIONTIME)\n",
    "from classifiers import inception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1645173668499,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "OzKp3I7V9QGT",
    "outputId": "3e38344b-8b79-46f6-91c3-745f5874b9a9"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1645173668501,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "mKuXSlsJ5E-V",
    "outputId": "72acead5-598e-4b19-a292-f38a12755433"
   },
   "outputs": [],
   "source": [
    "import sktime\n",
    "sktime.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZzFXpIuLniJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# initial filtering based on experimental setup\n",
    "def initial_filtering(data):\n",
    "    data = data[~data[\"comment\"].isin([\"stress_control\"])]\n",
    "    data = data[~data[\"comment\"].isin([\"H2B\"])]\n",
    "    data = data[data[\"guide\"].str.contains('1398') | data[\"guide\"].str.contains('1514')]\n",
    "    data = data[data[\"time\"] < 40]\n",
    "\n",
    "    return data\n",
    "\n",
    "#data = initial_filtering(data)\n",
    "\n",
    "#data.head()\n",
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgyZLuoYACS2"
   },
   "outputs": [],
   "source": [
    "def normalize_xy(data):\n",
    "    # add x and y max per time series\n",
    "    data = data.join(data.groupby(['file','particle'])['x'].max(), on=['file','particle'], rsuffix='_max')\n",
    "    data = data.join(data.groupby(['file','particle'])['y'].max(), on=['file','particle'], rsuffix='_max')\n",
    "    data = data.join(data.groupby(['file','particle'])['x'].min(), on=['file','particle'], rsuffix='_min')\n",
    "    data = data.join(data.groupby(['file','particle'])['y'].min(), on=['file','particle'], rsuffix='_min')\n",
    "\n",
    "    # normalize x and y\n",
    "    data['x_norm'] = data['x'] - data['x_min']\n",
    "    data['y_norm'] = data['y'] - data['y_min']\n",
    "\n",
    "    return data\n",
    "\n",
    "#data = normalize_xy(data)\n",
    "\n",
    "def create_instance_index(data):\n",
    "    # combine file and particle columns for using as instance index later on\n",
    "    data['fp'] = data['file'] + '__' + data['particle'].astype(str)\n",
    "    return data\n",
    "\n",
    "#data = create_instance_index(data)\n",
    "#data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aS35NYmz7X7a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def select_columns(data, cols):\n",
    "    data = data[cols]\n",
    "    return data\n",
    "\n",
    "#datam = data_to_multi_index(data)\n",
    "#datam.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kf8LtZ2fwiY4"
   },
   "outputs": [],
   "source": [
    "def nested_max(row, col_name='col'):\n",
    "    return row[col_name].max()\n",
    "\n",
    "def nested_size(row, col_name='col'):\n",
    "    return row[col_name].size\n",
    "\n",
    "def format_class_col(datan):\n",
    "    datan['class'] = datan.apply(nested_max, axis=1, col_name='serum_conc_percent')\n",
    "    datan['class'] = (datan['class'] / 10).astype('int')\n",
    "\n",
    "    datan = datan.drop(columns=['serum_conc_percent'])\n",
    "    return datan\n",
    "\n",
    "def add_nframes_col_nested(datan, col):\n",
    "    datan['nframes_nested'] = datan.apply(nested_size, axis=1, col_name=col)\n",
    "    return datan\n",
    "\n",
    "def add_nframes_col(data):\n",
    "    #datan['nframes'] = datan.apply(nested_size, axis=1, col_name=col)\n",
    "    data = data.copy()\n",
    "    #data['nframes'] = data.groupby('fp')['frame'].transform('max') + 1\n",
    "    data['nframes'] = data.groupby('fp')['frame'].transform('count')\n",
    "    \n",
    "    return data\n",
    "\n",
    "#datan = from_multi_index_to_nested(datam, instance_index='fp')\n",
    "#datan = add_nframes_col(datan)\n",
    "#datan = format_class_col(datan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5moxk8o5zxK"
   },
   "outputs": [],
   "source": [
    "#tmp = create_instance_index(data)\n",
    "#tmp = add_nframes_col(tmp)\n",
    "#tmp.groupby(by=['fp'])['frame','nframes'].min()\n",
    "#tmp['nframes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Jpu10G-U9DT"
   },
   "outputs": [],
   "source": [
    "#datan['class'].unique()\n",
    "#datan.head(2)\n",
    "#datan.groupby('nframes').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJ2T7VGiNABw"
   },
   "outputs": [],
   "source": [
    "def fix_unequal_frame_counts(datan, n):\n",
    "    # drop all series where frame count is not n\n",
    "    datan = datan[datan['nframes']==n]\n",
    "    return datan\n",
    "    \n",
    "#datan = fix_unequal_frame_counts(datan)\n",
    "#datan.groupby('nframes').count()\n",
    "\n",
    "def separate_observations_and_classes(datan):\n",
    "    # separate class vector...\n",
    "    y = datan['class'].values\n",
    "    datan = datan.drop(columns=['class'])\n",
    "    #print(datan.head())\n",
    "\n",
    "    # ... and observations\n",
    "    X = from_nested_to_3d_numpy(datan)\n",
    "    return X,y\n",
    "\n",
    "#X,y = separate_observations_and_classes(datan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5L9Go91TIT0x"
   },
   "outputs": [],
   "source": [
    "#print(X.shape)\n",
    "#print(y.shape)\n",
    "#print(Y.shape)\n",
    "#print(Y[:15,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qekRJSmDA8yU"
   },
   "outputs": [],
   "source": [
    "def displacement(row):\n",
    "    return math.sqrt(row['dx']**2 + row['dy']**2)\n",
    "\n",
    "def angle(row):\n",
    "    return math.atan(row['dy'] / row['dx'])\n",
    "\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # displacement\n",
    "    df['dx'] = df['x'].diff()\n",
    "    df['dy'] = df['y'].diff()\n",
    "    df['dxy'] = df.apply(displacement, axis=1)\n",
    "    df = df[df['frame']!=0]\n",
    "    #df = df.reset_index()\n",
    "\n",
    "    # direction\n",
    "    df['angle'] = df.apply(angle, axis=1)\n",
    "    df['dangle'] = df['angle'].diff()\n",
    "\n",
    "    # changes in area and perimeter\n",
    "    df['dperimeter'] = df['perimeter_au'].diff()\n",
    "    df['darea'] = df['area_micron'].diff()\n",
    "    df = df[df['frame']!=1]\n",
    "  \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1645173668911,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "6JwHVi5-X56p",
    "outputId": "a4e061a2-c157-4e88-8345-74b1eefc8b0e"
   },
   "outputs": [],
   "source": [
    "# feature sets\n",
    "# file is included in the first set because it is needed to create groups later on\n",
    "fsets = {}\n",
    "fsets['f_mot'] = ['x','y','min_dist_pxs','serum_conc_percent','file']\n",
    "fsets['f_mot_morph'] = fsets['f_mot'] + ['area_micron','perimeter_au']\n",
    "fsets['f_mot_morph_dyn'] = fsets['f_mot'] + ['dxy','angle','dangle','darea','dperimeter']\n",
    "\n",
    "print(fsets['f_mot_morph_dyn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIFjS4_Oetas"
   },
   "outputs": [],
   "source": [
    "def prepare_Xy(data, f_set_name):\n",
    "    data = data.copy()\n",
    "    data = initial_filtering(data)\n",
    "    #data = normalize_xy(data)\n",
    "    data = create_instance_index(data)\n",
    "    data = add_nframes_col(data)\n",
    "    debug0 = data.copy()\n",
    "    #print(data.nframes.unique())\n",
    "    #print(data.groupby(by=['nframes']).count())\n",
    "    # keep rows that have the maximum number of frames\n",
    "    idxmax = data.groupby(by=['nframes']).count()['file'].idxmax()\n",
    "    data = fix_unequal_frame_counts(data, idxmax)\n",
    "    #print(data.nframes.unique())\n",
    "\n",
    "    datam = data.set_index(['fp','frame'])\n",
    "    datam.replace(to_replace=pd.NA, value=None, inplace=True)\n",
    "\n",
    "    cols = fsets[f_set_name]\n",
    "    datam = datam[cols]\n",
    "    debug1 = datam.copy()\n",
    "\n",
    "    datan = from_multi_index_to_nested(datam, instance_index='fp')\n",
    "    datan.to_csv(SCRIPTS + \"/datan.csv\", index=False)\n",
    "    debug2 = datan.copy()\n",
    "    \n",
    "    #print(datan['file'])\n",
    "    # read group name from the last element of the series\n",
    "    # index of first element might be 0,1 or 2, depending on how many elements\n",
    "    # have been dropped because of adding features with df.diff()\n",
    "    groups = datan['file'].apply(lambda x: x.iloc[-1])\n",
    "    datan = datan.drop(columns=['file'])\n",
    "    \n",
    "    datan = format_class_col(datan)\n",
    "    dfX = datan.drop(columns=['class'])\n",
    "\n",
    "    #datan = add_nframes_col_nested(datan, 'x_norm')\n",
    "    debug_data = datan.copy()\n",
    "    #return debug_data\n",
    "    X,y = separate_observations_and_classes(datan)\n",
    "    return X, dfX, y, groups, debug1, debug2\n",
    "\n",
    "#tmp = pipeline_xy(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10210,
     "status": "ok",
     "timestamp": 1645173679100,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "OyVb8wEJr_l_",
    "outputId": "f7fa7844-946f-42e4-a55c-9186634d03d5"
   },
   "outputs": [],
   "source": [
    "''' \n",
    "read the data \n",
    "'''\n",
    "\n",
    "data_file = Path(SCRIPTS) / '63455ea_data_chromatin_live.csv'\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "data = add_features(data)\n",
    "X, dfX, y, groups, debugm, debugn = prepare_Xy(data, 'f_mot')\n",
    "\n",
    "#test_data_file = directory / 'a286935_data_chromatin_live.csv'\n",
    "#test_data = pd.read_csv(test_data_file)\n",
    "#test_X, test_y, groups, debug_polar, debug_data = pipeline_xy(test_data, exclude_border=exclude_border)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1645173679106,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "MoYYQ59cmrsj",
    "outputId": "193a11af-5054-47e3-ee43-68af201dbc9e"
   },
   "outputs": [],
   "source": [
    "debugm.isnull().values.any()\n",
    "data.head()\n",
    "debugn['file'][0]\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ckn18-2G1pxa"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "scoring=['accuracy', 'precision','recall','f1']\n",
    "def print_score_mean_and_std(scores):\n",
    "    for k in scores.keys():\n",
    "        if \"test\" in k:\n",
    "            print(k + ' mean: ' + str(np.mean(scores[k])))\n",
    "            print(k + ' std: ' + str(np.std(scores[k])))\n",
    "\n",
    "def format_scores_df(scores):\n",
    "    scores = scores.drop(columns=['fit_time','score_time'])\n",
    "    scores.columns = scores.columns.str.replace('test_','')\n",
    "    #print(scores.mean())\n",
    "    #print(scores.std())\n",
    "    return scores\n",
    "\n",
    "def cv_gkf(classifier, X, y, groups, splits):\n",
    "    cv = GroupKFold(n_splits=splits)\n",
    "    scores = cross_validate(classifier, X, y, cv=cv, scoring=scoring, groups=groups)\n",
    "    print(classifier)\n",
    "    print(cv)\n",
    "    print_score_mean_and_std(scores)\n",
    "    print()\n",
    "    return scores\n",
    "\n",
    "def cv_gkf_single_score(classifier, X, y, groups, splits):\n",
    "    cv = GroupKFold(n_splits=splits)\n",
    "    scores = cross_val_score(classifier, X, y, cv=cv, groups=groups)\n",
    "    print(classifier)\n",
    "    print(cv)\n",
    "    print('accuracy mean: ' + str(scores.mean()))\n",
    "    print('accuracy std: ' + str(scores.std()))\n",
    "    #print_score_mean_and_std(scores)\n",
    "    print()\n",
    "    return scores\n",
    "\n",
    "def cv_gss(classifier, X, y, groups):\n",
    "    cv = GroupShuffleSplit(n_splits=20, test_size=0.25, random_state=0)\n",
    "    scores = cross_validate(classifier, X, y, cv=cv, scoring=scoring, groups=groups)\n",
    "    print(classifier)\n",
    "    print(cv)\n",
    "    print_score_mean_and_std(scores)\n",
    "    print()\n",
    "    return scores\n",
    "\n",
    "def cv_gss_single_score(classifier, X, y, groups):\n",
    "    cv = GroupShuffleSplit(n_splits=20, test_size=0.25, random_state=0)\n",
    "    scores = cross_val_score(classifier, X, y, cv=cv, groups=groups)\n",
    "    print(classifier)\n",
    "    print(cv)\n",
    "    print('accuracy mean: ' + str(scores.mean()))\n",
    "    print('accuracy std: ' + str(scores.std()))\n",
    "    print()\n",
    "    return scores\n",
    "\n",
    "def cv_logo(classifier, X, y, groups):\n",
    "    cv = LeaveOneGroupOut()\n",
    "    scores = cross_validate(classifier, X, y, cv=cv, scoring=scoring, groups=groups)\n",
    "    print(classifier)\n",
    "    print(cv)\n",
    "    print_score_mean_and_std(scores)\n",
    "    print()\n",
    "    return scores\n",
    "\n",
    "\n",
    "def cv_sgkf(classifier, X, y, groups, repeats=10):\n",
    "    cv = StratifiedGroupKFold(n_splits=4, shuffle=True)\n",
    "    #print(classifier)\n",
    "    #print(cv)\n",
    "\n",
    "    scores_all = []\n",
    "    for i in range(repeats):\n",
    "        #cv = StratifiedGroupKFold(n_splits=4, shuffle=True)\n",
    "        scores = cross_validate(classifier, X, y, cv=cv, scoring=scoring, groups=groups)\n",
    "        scores_all.append(pd.DataFrame.from_dict(scores))\n",
    "    \n",
    "    scores = pd.concat(scores_all)\n",
    "    scores = format_scores_df(scores)\n",
    "    score = scores['cv'] = 'StratifiedGroupKFold'\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1645194867022,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "7gBnE-xkz_J7"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_data_for_inception(X,y,test_size=0.33):\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=43)\n",
    "    # use all data, use cross-validation\n",
    "    x_train = X.copy()\n",
    "    y_train = y.copy()\n",
    "    #x_test = X.copy()\n",
    "    #y_test = y.copy()\n",
    "\n",
    "    #nb_classes = len(np.unique(np.concatenate((y_train, y_test), axis=0)))\n",
    "    nb_classes = len(np.unique(np.concatenate((y_train,), axis=0)))\n",
    "\n",
    "    # make the min to zero of labels\n",
    "    #y_train, y_test = transform_labels(y_train, y_test)\n",
    "\n",
    "    # save orignal y because later we will use binary\n",
    "    #y_true = y_test.astype(np.int64)\n",
    "    y_true_train = y_train.astype(np.int64)\n",
    "    # transform the labels from integers to one hot vectors\n",
    "    enc = sklearn.preprocessing.OneHotEncoder()\n",
    "    #enc.fit(np.concatenate((y_train, y_test), axis=0).reshape(-1, 1))\n",
    "    enc.fit(np.concatenate((y_train,), axis=0).reshape(-1, 1))\n",
    "    y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "    #y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "    if len(x_train.shape) == 2:  # if univariate\n",
    "        # add a dimension to make it multivariate with one dimension\n",
    "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "        #x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "    #return x_train, y_train, x_test, y_test, y_true, nb_classes, y_true_train, enc\n",
    "    return x_train, y_train, nb_classes, y_true_train, enc\n",
    "\n",
    "'''\n",
    "def fit_classifier():\n",
    "    input_shape = x_train.shape[1:]\n",
    "\n",
    "    classifier = create_classifier(classifier_name, input_shape, nb_classes,\n",
    "                                   output_directory)\n",
    "\n",
    "    classifier.fit(x_train, y_train, x_test, y_test, y_true)\n",
    "\n",
    "\n",
    "def create_classifier(classifier_name, input_shape, nb_classes, output_directory,\n",
    "                      verbose=False, build=True):\n",
    "    if classifier_name == 'nne':\n",
    "        from classifiers import nne\n",
    "        return nne.Classifier_NNE(output_directory, input_shape,\n",
    "                                  nb_classes, verbose)\n",
    "    if classifier_name == 'inception':\n",
    "        from classifiers import inception\n",
    "        return inception.Classifier_INCEPTION(output_directory, input_shape, nb_classes, verbose,\n",
    "                                              build=build)\n",
    "'''\n",
    "\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#CV_OUT = ROOT + \"/My Drive/Work/InceptionTime/cross-validation/\"\n",
    "\n",
    "#\n",
    "# Single cross-validation run\n",
    "#\n",
    "def inceptiontime_cv(cv, X_inc, y_inc, y_true, epochs=250, nb_classes=2):\n",
    "    output_directory = WRKROOT + \"/InceptionTime/test8cv/\"\n",
    "    #output_directory = ROOT + \"/My Drive/Work/InceptionTime/test2\"\n",
    "    input_shape = X.shape[1:]\n",
    "    verbose = False\n",
    "\n",
    "    classifier_keras = None\n",
    "    #classifier_keras = inception.Classifier_INCEPTION(output_directory, input_shape, nb_classes, \\\n",
    "    #                                                 nb_epochs=epochs, verbose=verbose)\n",
    "    def create_model():\n",
    "        #print(classifier_keras.model)\n",
    "        return classifier_keras.model\n",
    "\n",
    "    batch_size = int(min(X_inc.shape[0] / 10, 16))\n",
    "    columns = ['accuracy','precision','recall','f1']\n",
    "    scores = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # One-hot encoding is a problem for StratifiedGroupKFold,\n",
    "    # split using y_true\n",
    "    for train_index,val_index in cv.split(X_inc,y_true,groups):\n",
    "        #print('cv loop')\n",
    "        #print(train_index.shape)\n",
    "        #print(X_inc[train_index].shape)\n",
    "        input_shape = X_inc[train_index].shape[1:]\n",
    "        #print(input_shape)\n",
    "\n",
    "        #print(train_index)\n",
    "        #print(val_index)\n",
    "        #continue\n",
    "        #print(y_true[train_index])\n",
    "        #print(y_inc[train_index])\n",
    "        #break\n",
    "\n",
    "        classifier_keras = inception.Classifier_INCEPTION(output_directory, input_shape, nb_classes, \\\n",
    "                                                          nb_epochs=epochs, verbose=verbose)\n",
    "        classifier = KerasClassifier(model=create_model, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        classifier.fit(X_inc[train_index],y_inc[train_index])\n",
    "        pred = classifier.predict(X_inc[val_index])\n",
    "\n",
    "        truth = y_true[val_index]\n",
    "        #print('truth')\n",
    "        #print(truth)\n",
    "        #print('pred')\n",
    "        #print(pred)\n",
    "\n",
    "        # prediction is onehot-encoded, reverse it\n",
    "        pred = pred.argmax(1)\n",
    "        #print(pred)\n",
    "\n",
    "        # get fold accuracy and append\n",
    "        fold_acc = accuracy_score(truth, pred)\n",
    "        fold_prc = precision_score(truth, pred)\n",
    "        fold_rec = recall_score(truth, pred)\n",
    "        fold_f1 = f1_score(truth, pred)\n",
    "        scores.loc[len(scores)] = [fold_acc,fold_prc,fold_rec,fold_f1]\n",
    "    \n",
    "    scores['classifier'] = 'InceptionTime'\n",
    "    return scores\n",
    "\n",
    "#\n",
    "# Repeat cross-validation\n",
    "#\n",
    "def inceptiontime_cv_repeat(data, fset, epochs=250, repeats=10):\n",
    "    print(fset)\n",
    "    X, dfX, y, groups, debug_polar, debug_data = prepare_Xy(data, fset)\n",
    "\n",
    "    # for now, while testing cross-validation, prepare_data returns all data in both train and test sets\n",
    "    test_size = 0.3\n",
    "    X_inc, y_inc, nb_classes, y_true, enc = prepare_data_for_inception(X,y,test_size=test_size)\n",
    "\n",
    "    #print(X_inc.shape)\n",
    "    #print(y_inc.shape)\n",
    "\n",
    "    cv = StratifiedGroupKFold(n_splits=4, shuffle=True)\n",
    "    #cv = GroupKFold(n_splits=4)\n",
    "\n",
    "    scores_all = []\n",
    "    for i in range(repeats):\n",
    "        print('repeat: %d/%d' % (i+1, repeats))\n",
    "        scores = inceptiontime_cv(cv, X_inc, y_inc, y_true, epochs=epochs, nb_classes=nb_classes)\n",
    "        scores['repeat'] = i+1\n",
    "\n",
    "    scores['cv'] = str(cv)\n",
    "    scores['fset'] = fset\n",
    "    scores['epochs'] = epochs   \n",
    "\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 175060,
     "status": "ok",
     "timestamp": 1645194677022,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "0CiNCC87L0_T",
    "outputId": "ff20fad2-0df7-450f-d0f4-6973c0a21822"
   },
   "outputs": [],
   "source": [
    "scores_all = []\n",
    "for fset in fsets.keys():\n",
    "    scores = inceptiontime_cv_repeat(data, fset, epochs=3, repeats=2)\n",
    "    scores_all.append(scores)\n",
    "    \n",
    "scores_inceptiontime = pd.concat(scores_all)\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%Y-%m%d-%H%M\")\n",
    "\n",
    "from pathlib import Path\n",
    "excel = Path(CV_OUT) / (\"inceptiontime_\" + now + \".xlsx\")\n",
    "scores_inceptiontime.to_excel(excel, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 929,
     "status": "ok",
     "timestamp": 1645193042976,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "Cefnjldc51Gz",
    "outputId": "98cec718-4cb2-462a-e923-0036c38f9b4e"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(scores_inceptiontime.groupby(['fset','epochs']).agg([np.mean]))\n",
    "print(scores_inceptiontime.groupby(['fset','epochs']).std())#agg([np.std]))\n",
    "print(scores_inceptiontime.shape)\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.stats import sem\n",
    "acc = scores_inceptiontime.groupby(['classifier','cv','fset']).agg([np.mean, np.std, sem])['accuracy']\n",
    "acc.plot(title='Accuracy', kind='barh', y='mean', xerr='std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1645181672876,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "e20iO3Rnaob4",
    "outputId": "4028e7d4-2fa0-4ef2-9c0c-386cfbcb82ec"
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1645181727087,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "t8ZNAf8u9gk9",
    "outputId": "0e80bfc1-9324-4038-b464-453cd8c48444"
   },
   "outputs": [],
   "source": [
    "scores.groupby(['cv','fest','epochs']).agg([np.mean, np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1645182073088,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "An1QiuBMWoTX",
    "outputId": "dfbafd03-495f-4295-a091-4f2379c31fc0"
   },
   "outputs": [],
   "source": [
    "acc\n",
    "np.std(acc, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1645180464841,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "potmqyiwWaGs",
    "outputId": "f847e7cd-2ea9-4ef3-d479-38e0f911bc84"
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame([3,4,5,6], columns=scoring)\n",
    "df = pd.DataFrame(columns=scoring)\n",
    "df.loc[len(df)] = [3,4,5,6]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64797,
     "status": "ok",
     "timestamp": 1645168949003,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "A4XyAFZcxGJa",
    "outputId": "8e16cdbc-a2d7-4390-d41a-24ec60028cc2"
   },
   "outputs": [],
   "source": [
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "classifier = KNeighborsTimeSeriesClassifier(n_neighbors=5)\n",
    "\n",
    "scores_all = []\n",
    "for fset in fsets.keys():\n",
    "    #print()\n",
    "    #print(\"####\")\n",
    "    #print(\"Feature set:\" + fset)\n",
    "    #print(\"####\")\n",
    "    X, dfX, y, groups, debug_polar, debug_data = prepare_Xy(data, fset)\n",
    "\n",
    "    scores = cv_sgkf(classifier, X, y, groups, repeats=20)\n",
    "    scores['classifier'] = 'KNeighborsTSC'\n",
    "    scores['fset'] = fset\n",
    "    scores_all.append(scores)\n",
    "    #break\n",
    "    #scores2 = cv_gss(classifier, X, y, groups)\n",
    "    #scores3 = cv_logo(classifier, X, y, groups)\n",
    "\n",
    "\n",
    "scores_kneighbors = pd.concat(scores_all)\n",
    "print(scores_kneighbors.groupby(['cv','fset']).mean())\n",
    "print(scores_kneighbors.groupby(['cv','fset']).std())\n",
    "print(scores_kneighbors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1645168949520,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "PKb4Ui4ushi7",
    "outputId": "8e257252-bd56-493f-8eab-e8ba59d1802d"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.stats import sem\n",
    "acc = scores_kneighbors.groupby(['classifier','cv','fset']).agg([np.mean, np.std, sem])['accuracy']\n",
    "acc.plot(title='Accuracy', kind='barh', y='mean', xerr='std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 368374,
     "status": "ok",
     "timestamp": 1645169317873,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "JtmQVHbpVWaW",
    "outputId": "8d63fc72-6875-416f-c392-f0ff492463c3"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "#classifier = RidgeClassifier()\n",
    "#classifier.fit(X_transform, y)\n",
    "\n",
    "\n",
    "scores_all = []\n",
    "for fset in fsets.keys():\n",
    "    #print(fset)\n",
    "    X, dfX, y, groups, debugm, debugn = prepare_Xy(data, fset)\n",
    "\n",
    "    rocket = Rocket()  # by default, ROCKET uses 10,000 kernels\n",
    "    rocket.fit(dfX)\n",
    "    X_transform = rocket.transform(dfX)\n",
    "\n",
    "    #classifier.fit(X_transform, y)\n",
    "    #scores = classifier.score(X_transform, y)\n",
    "    #print_score_mean_and_std(scores)\n",
    "    scores = cv_sgkf(classifier, X_transform, y, groups, repeats=20)\n",
    "    scores['classifier'] = 'Rocket'\n",
    "    scores['fset'] = fset\n",
    "    scores_all.append(scores)\n",
    "\n",
    "    #scores1 = cv_gkf(classifier, X_transform, y, groups, 4)\n",
    "    #scores1 = cv_gss(classifier, X_transform, y, groups)\n",
    "    #scores1 = cv_logo(classifier, X_transform, y, groups)\n",
    "    \n",
    "scores_rocket = pd.concat(scores_all)\n",
    "print(scores_rocket.groupby(['cv','fset']).mean())\n",
    "print(scores_rocket.groupby(['cv','fset']).std())\n",
    "print(scores_rocket.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1645169318290,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "cw2SSm-2T_Ba",
    "outputId": "bf079c3d-6de7-4522-fa50-c598dde57815"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.stats import sem\n",
    "acc = scores_rocket.groupby(['classifier','cv','fset']).agg([np.mean, np.std, sem])['accuracy']\n",
    "acc.plot(title='Accuracy', kind='barh', y='mean', xerr='std')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKCjuHA7JaBx"
   },
   "source": [
    "\n",
    "\n",
    "1.   Stratified split (add function, with loop)\n",
    "2.   Infinity loop to check epoch effect for inceptiontime\n",
    "3.   SHAP for NN, TSC\n",
    "4.   plot acc (mean, std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3165,
     "status": "ok",
     "timestamp": 1643987142017,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "jcn77c7_rqgd",
    "outputId": "b3efa618-c8b5-4967-e086-527694ff799d"
   },
   "outputs": [],
   "source": [
    "# https://www.sktime.org/en/stable/examples/rocket.html\n",
    "\n",
    "sklearn.__version__\n",
    "from sktime.datasets import load_basic_motions  # multivariate dataset\n",
    "X_train, y_train = load_basic_motions(split=\"train\", return_X_y=True)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "#X_train.info()\n",
    "#y_train\n",
    "#X\n",
    "#X_train.head()\n",
    "\n",
    "rocket = Rocket()\n",
    "rocket.fit(X_train)\n",
    "X_train_transform = rocket.transform(X_train)\n",
    "\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
    "classifier.fit(X_train_transform, y_train)\n",
    "classifier.score(X_train_transform, y_train)\n",
    "\n",
    "#X_test, y_test = load_basic_motions(split=\"test\", return_X_y=True)\n",
    "#X_test_transform = rocket.transform(X_test)\n",
    "\n",
    "#classifier.score(X_test_transform, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "executionInfo": {
     "elapsed": 4211007,
     "status": "error",
     "timestamp": 1637329895289,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -120
    },
    "id": "ghIN8jbAYaSb",
    "outputId": "91e715c5-d508-4fe3-b0f6-4ff49d65ee4b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "##\n",
    "## This is too slow, skip...\n",
    "##\n",
    "\n",
    "# https://stackoverflow.com/questions/57015499/how-to-use-dynamic-time-warping-with-knn-in-python\n",
    "#custom metric\n",
    "def DTW(a, b):   \n",
    "    an = a.size\n",
    "    bn = b.size\n",
    "    pointwise_distance = distance.cdist(a.reshape(-1,1),b.reshape(-1,1))\n",
    "    cumdist = np.matrix(np.ones((an+1,bn+1)) * np.inf)\n",
    "    cumdist[0,0] = 0\n",
    "\n",
    "    for ai in range(an):\n",
    "        for bi in range(bn):\n",
    "            minimum_cost = np.min([cumdist[ai, bi+1],\n",
    "                                   cumdist[ai+1, bi],\n",
    "                                   cumdist[ai, bi]])\n",
    "            cumdist[ai+1, bi+1] = pointwise_distance[ai,bi] + minimum_cost\n",
    "\n",
    "    return cumdist[an, bn]\n",
    "\n",
    "#train\n",
    "#parameters = {'n_neighbors':[2, 4, 8]}\n",
    "classifier = KNeighborsClassifier(metric=DTW, n_neighbors=5)\n",
    "#classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "for fset in fsets.keys():\n",
    "    print(fset)\n",
    "    X, dfX, y, groups, debug_polar, debug_data = prepare_Xy(data, fset)\n",
    "\n",
    "    # https://stackoverflow.com/questions/34972142/sklearn-logistic-regression-valueerror-found-array-with-dim-3-estimator-expec\n",
    "    nsamples, nx, ny = X.shape\n",
    "    Xrs = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "    #scores1 = cv_gkf(classifier, X, y, groups, 4)\n",
    "    scores1 = cv_gkf(classifier, Xrs, y, groups, 4)\n",
    "    #scores2 = cv_gss(classifier, Xrs, y, groups)\n",
    "    #scores3 = cv_logo(classifier, Xrs, y, groups)\n",
    "\n",
    "    break\n",
    "\n",
    "# These don't work with multi-variate time series\n",
    "\n",
    "from sktime.classification.distance_based import ElasticEnsemble\n",
    "classifier = ElasticEnsemble()\n",
    "scores = cv_gkf(classifier, X, y, groups, 30)\n",
    "\n",
    "from sktime.classification.hybrid import HIVECOTEV1\n",
    "classifier = HIVECOTEV1()\n",
    "scores = cv_gkf(classifier, X, y, groups, 30)\n",
    "\n",
    "from sktime.classification.interval_based import SupervisedTimeSeriesForest\n",
    "classifier = SupervisedTimeSeriesForest()\n",
    "scores = cv_gkf(classifier, X, y, groups, 30)\n",
    "\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "classifier = TimeSeriesForestClassifier()\n",
    "scores = cv_gkf(classifier, X, y, groups, 30)\n",
    "\n",
    "from dtaidistance import dtw\n",
    "\n",
    "# https://stackoverflow.com/questions/57015499/how-to-use-dynamic-time-warping-with-knn-in-python\n",
    "\n",
    "classifier = KNeighborsClassifier(metric=dtw.distance, n_neighbors=3)\n",
    "scores1 = cv_gkf(classifier, d2_train_dataset, y, groups, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 2376,
     "status": "ok",
     "timestamp": 1634128537764,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "7tMkRbr4nr81",
    "outputId": "a133b2df-43f7-441e-d680-507fd304dbaf"
   },
   "outputs": [],
   "source": [
    "classifier.predict(test_X, test_y, None, None, None, return_df_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1634112094393,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "dLb_SdYgsFlc",
    "outputId": "7ef6d568-13d4-4be8-ecfa-473391216710"
   },
   "outputs": [],
   "source": [
    "classifier.predict(X, y, None, None, None, return_df_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1634112013676,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "FmFdatzQiaFB",
    "outputId": "f10cb198-96fc-414f-852b-12bbc9974aa9"
   },
   "outputs": [],
   "source": [
    "data.plot(x='x', y='y', kind='scatter')\n",
    "test_data.plot(x='x', y='y', kind='scatter')\n",
    "X[1::]\n",
    "X\n",
    "test_X[1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1634112106859,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "Kq5GmXpa7VGt",
    "outputId": "b9fe3c21-fdb9-42de-b578-2b9b57a4f2df"
   },
   "outputs": [],
   "source": [
    "history = pd.read_csv(output_directory + \"history.csv\")\n",
    "history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1633528784619,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "dlaGKRxicG11",
    "outputId": "659f4987-03b1-434c-93dd-bed4ff3236e3"
   },
   "outputs": [],
   "source": [
    "data.groupby(by=['serum_conc_percent'])['file'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1633528808262,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "NTJO_0sPcQ4U",
    "outputId": "aa697cc0-5dee-4b58-b597-bb35376593dd"
   },
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1634112121695,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "ktlDw-iwoHoT",
    "outputId": "7c60e3d8-d725-45f4-efc0-40bf92917bf8"
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plt.figure()\n",
    "history.plot(y=[\"accuracy\",\"val_accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1633603034263,
     "user": {
      "displayName": "Harri Jäälinoja",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10358975484852623681"
     },
     "user_tz": -180
    },
    "id": "7qVL3RYDUUio",
    "outputId": "3ad2d522-489c-4bd4-9b35-cb6295e17f36"
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NY1R4XMGU1Fm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMszOeNv++Q/0PlvcMwSp5H",
   "collapsed_sections": [],
   "name": "n_track_InceptionTime.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tsc_jupyter)",
   "language": "python",
   "name": "tsc_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
